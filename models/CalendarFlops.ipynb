{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CalendarFlops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: de_core_news_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.0.0/de_core_news_sm-2.0.0.tar.gz#egg=de_core_news_sm==2.0.0 in /opt/conda/lib/python3.6/site-packages (2.0.0)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\n",
      "\u001b[93m    Linking successful\u001b[0m\n",
      "    /opt/conda/lib/python3.6/site-packages/de_core_news_sm -->\n",
      "    /opt/conda/lib/python3.6/site-packages/spacy/data/de\n",
      "\n",
      "    You can now load the model via spacy.load('de')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Dataset, BucketIterator, Field, TabularDataset, Iterator\n",
    "from torchtext.vocab import Vocab\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "from torchtext.vocab import Vectors\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read set\n",
    "#data='../datasets/TalentFox/processed_dataset-small.csv'\n",
    "data='../datasets/TalentFox/processed_dataset.csv'\n",
    "\n",
    "parced_data = pd.read_csv(data)\n",
    "parced_data = parced_data[['candidate_resume','job_description', 'match_status']]\n",
    "parced_data['match_status'] = parced_data['match_status'][pd.to_numeric(parced_data['match_status'], errors='coerce').notnull()]\n",
    "parced_data = parced_data.dropna()\n",
    "\n",
    "# Max length\n",
    "max_len = 5000\n",
    "min_len = 100\n",
    "filt_candidate = parced_data[\"candidate_resume\"].map(lambda x: len(x)) > min_len\n",
    "parced_data = parced_data[filt_candidate]\n",
    "#Flat\n",
    "parced_data['match_status'] = parced_data['match_status'].apply(lambda x: 0 if int(x) < 2 else 1)\n",
    "\n",
    "# Drop to equal\n",
    "parced_data = parced_data.sort_values(by=['match_status'], ascending=False)\n",
    "count = pd.value_counts(parced_data['match_status'].values, sort=False)\n",
    "count = count[1]\n",
    "parced_data = parced_data[:2*count]\n",
    "\n",
    "# Shuffle\n",
    "parced_data = parced_data.sample(frac=1)\n",
    "\n",
    "max_length_candidates = max((len(s.split(' ')) for s in parced_data['candidate_resume']))\n",
    "max_length_jobs = max((len(s.split(' ')) for s in parced_data['job_description']))\n",
    "\n",
    "sizes = [0.7, 0.2]\n",
    "n = len(parced_data)\n",
    "\n",
    "train_size = int(sizes[0] * n)\n",
    "val_size = int(sizes[1] * n)\n",
    "test_size = n - train_size - val_size\n",
    "\n",
    "train = parced_data[:train_size]\n",
    "val = parced_data[train_size:train_size+val_size]\n",
    "test = parced_data[train_size+val_size:]\n",
    "\n",
    "val.to_csv('../datasets/TalentFox/val.csv', header = False, index = False)\n",
    "test.to_csv('../datasets/TalentFox/test.csv', header = False, index = False)\n",
    "train.to_csv('../datasets/TalentFox/train.csv', header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1636\n"
     ]
    }
   ],
   "source": [
    "print(len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_de = spacy.load('de')\n",
    "\n",
    "vec_url = 'https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki.de.vec'\n",
    "\n",
    "def tokenizer(text): # create a tokenizer function\n",
    "    return [tok.text for tok in spacy_de.tokenizer(text)]\n",
    "\n",
    "\n",
    "CANDIDATES = Field(sequential=True, lower=True, include_lengths=True, fix_length=max_length_candidates, tokenize=tokenizer)\n",
    "LABEL = Field(sequential=False, use_vocab=False)\n",
    "JOBS = Field(sequential=True, lower=True, include_lengths=True, fix_length=max_length_jobs, tokenize=tokenizer)\n",
    "\n",
    "train, val, test = TabularDataset.splits(\n",
    "        path='../datasets/TalentFox', train='train.csv',\n",
    "        validation='val.csv', test='test.csv', format='csv',\n",
    "        fields=[('Candidates', CANDIDATES), ('Jobs', JOBS), ('Label', LABEL)])\n",
    "\n",
    "CANDIDATES.build_vocab(train, vectors=Vectors('wiki.de.vec', url=vec_url))\n",
    "LABEL.build_vocab(train)\n",
    "JOBS.build_vocab(train, vectors=Vectors('wiki.de.vec', url=vec_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text fields:\n",
      " Size of  job vocabulary: 11993\n",
      " Size of users vocabulary: 50284\n",
      " no. times the \"das\" appear in the dataset: 835\n",
      " Max length: Candidates: 3541, Jobs: 401\n"
     ]
    }
   ],
   "source": [
    "print('Text fields:')\n",
    "print(f' Size of  job vocabulary: {len(JOBS.vocab)}')\n",
    "print(f' Size of users vocabulary: {len(CANDIDATES.vocab)}')\n",
    "print(' no. times the \"das\" appear in the dataset:', JOBS.vocab.freqs['das']+CANDIDATES.vocab.freqs['das'])\n",
    "print(f' Max length: Candidates: {max_length_candidates}, Jobs: {max_length_jobs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = (10, 11, 12)\n",
    "\n",
    "train_iter, val_iter, test_iter = BucketIterator.splits(\n",
    "    (train, val, test), batch_sizes = batch_size, sort_key=lambda x: len(x.Jobs), sort_within_batch = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of candidates: 50284, Number of jobs: 11993\n",
      "Candidates embedding dim 300\n",
      "Job embedding dim 300\n"
     ]
    }
   ],
   "source": [
    "# size of embeddings\n",
    "embedding_dim_candidates = CANDIDATES.vocab.vectors.size()[1]\n",
    "embedding_dim_jobs = JOBS.vocab.vectors.size()[1]\n",
    "num_jobs = JOBS.vocab.vectors.size()[0]\n",
    "num_candidates = CANDIDATES.vocab.vectors.size()[0]\n",
    "print(f'Number of candidates: {num_candidates}, Number of jobs: {num_jobs}')\n",
    "\n",
    "print(f'Candidates embedding dim {embedding_dim_candidates}')\n",
    "print(f'Job embedding dim {embedding_dim_jobs}')\n",
    "\n",
    "n_hidden = 91\n",
    "l1_hidden = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFNN(nn.Module):\n",
    "    def __init__(self, num_candidates,\n",
    "                 num_jobs,\n",
    "                 embedding_dim_candidates=embedding_dim_candidates,\n",
    "                 embedding_dim_jobs=embedding_dim_jobs,\n",
    "                 n_hidden=n_hidden,\n",
    "                 l1_hidden=l1_hidden):\n",
    "        super(CFNN, self).__init__()\n",
    "        \n",
    "        self.candidates_emb = nn.Embedding(num_candidates, embedding_dim_candidates)       \n",
    "        self.jobs_emb = nn.Embedding(num_jobs, embedding_dim_jobs)\n",
    "               \n",
    "        self.lin1 = nn.Linear(embedding_dim_candidates + embedding_dim_jobs, l1_hidden)\n",
    "        self.lin2 = nn.Linear(l1_hidden, 1)\n",
    "        self.drop0 = nn.Dropout(0.1)\n",
    "        self.drop1 = nn.Dropout(0.1)\n",
    "                \n",
    "        ### RNN decoding\n",
    "        # Candidates\n",
    "        self.rnn_candidates = nn.LSTM(embedding_dim_candidates, n_hidden, batch_first = False)\n",
    "        self.rnnlin_candidates = nn.Linear(embedding_dim_candidates, n_hidden)\n",
    "        \n",
    "        # Jobs\n",
    "        self.rnn_jobs = nn.LSTM(embedding_dim_jobs, n_hidden, batch_first = False)\n",
    "        self.rnnlin_jobs = nn.Linear(100, n_hidden)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, c, j, hidden_candidates, hidden_jobs, candidates_length, job_length):\n",
    "        C = self.candidates_emb(c)\n",
    "        J = self.jobs_emb(j)\n",
    "        batch_size = len(candidates_length)\n",
    "        \n",
    "        # Masking and meaning Candidates\n",
    "        mask_candidates = list()\n",
    "        for i in range(batch_size):\n",
    "            l = candidates_length.data[0].item()\n",
    "            m = [1]*l + [0]*(max_length_candidates-l)\n",
    "            mask_candidates += [m]       \n",
    "        mask_candidates = torch.from_numpy(np.array(mask_candidates)).to(device).float().transpose(0,1)             \n",
    "        mask_candidates = mask_candidates.unsqueeze(2)\n",
    "        \n",
    "        C = C * mask_candidates\n",
    "        C = C.sum(0)/candidates_length.unsqueeze(1).float().to(device)\n",
    "\n",
    "        # Masking and meaning Jobs\n",
    "        mask_jobs = list()\n",
    "        for i in range(batch_size):\n",
    "            l = job_length.data[0].item()\n",
    "            m = [1]*l + [0]*(max_length_jobs-l)\n",
    "            mask_jobs += [m]       \n",
    "        mask_jobs = torch.from_numpy(np.array(mask_jobs)).to(device).float().transpose(0,1)\n",
    "        mask_jobs = mask_jobs.unsqueeze(2)\n",
    "        \n",
    "        J = J * mask_jobs\n",
    "        J = J.sum(0)/job_length.unsqueeze(1).float().to(device)\n",
    "        \n",
    "        x = torch.cat([C, J], dim=1)\n",
    "        \n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = F.relu(self.lin2(x))\n",
    "\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "    def init_hidden_candidates(self, batch_size):\n",
    "        init = torch.zeros(1, batch_size, n_hidden).to(device)\n",
    "        return (init,init)\n",
    "    \n",
    "    def init_hidden_jobs(self, batch_size):\n",
    "        init = torch.zeros(1, batch_size, n_hidden).to(device)\n",
    "        return (init,init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training loop\n",
    "def train(model, train_loader, optimizer, criterion, epoch, print_batch_p):\n",
    "    model.train()\n",
    "    \n",
    "    TP,FP,TN,FN = 0,0,0,0\n",
    "    loss_list = []\n",
    "    \n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        (candidates, candidates_length), (jobs, job_length), ratings = data\n",
    "                   \n",
    "        batch_s = len(candidates_length)\n",
    "        \n",
    "        candidates = candidates.long().to(device)\n",
    "        jobs = jobs.long().to(device)\n",
    "        ratings = ratings.float().to(device)      \n",
    "        ratings = ratings.view(-1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        hidden_init_candidates = model.init_hidden_candidates(batch_s)\n",
    "        hidden_init_jobs = model.init_hidden_jobs(batch_s)\n",
    "        output = model(candidates, jobs, hidden_init_candidates, hidden_init_jobs, candidates_length, job_length)\n",
    "        output = output.view(-1)\n",
    "        \n",
    "        loss = criterion(output, ratings)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print jumping\n",
    "        percent = print_batch_p\n",
    "        \n",
    "        proc = int((len(train_loader.dataset)/batch_s)*percent)\n",
    "        proc = proc if proc >= 1 else 1\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        output_flat = [0 if o < 0.5 else 1 for o in output.data]\n",
    "\n",
    "        for y,yhat in zip(ratings.data, output_flat):\n",
    "            y = int(y)\n",
    "            if yhat == 0:\n",
    "                if y != yhat:\n",
    "                    FN += 1\n",
    "                else:\n",
    "                    TN += 1\n",
    "            else:\n",
    "                if y != yhat:\n",
    "                    FP += 1\n",
    "                else:\n",
    "                    TP += 1\n",
    "        loss_list += [loss.item()]\n",
    "        \n",
    "        if batch_idx % proc == 0 and batch_idx != 0:\n",
    "            loss_mean = sum(loss_list)/len(loss_list)\n",
    "            acc = (TP + TN)/(TP+FP+TN+FN)\n",
    "            \n",
    "            if TP + FN == 0:\n",
    "                recall = 0    \n",
    "            else:       \n",
    "                recall = TP/(TP + FN)\n",
    "                \n",
    "            if TP + FP == 0:\n",
    "                precision = 0\n",
    "            else:\n",
    "                precision = TP/(TP + FP)\n",
    "            \n",
    "            \n",
    "            if recall + precision == 0:\n",
    "                F1_score = 0\n",
    "            else:\n",
    "                F1_score = 2/(1/recall + 1/precision)\n",
    "            \n",
    "            #TP,FP,TN,FN = 0,0,0,0\n",
    "            #loss_list = []\n",
    "            print(f'Train epoch {epoch} ({100 * (batch_idx / len(train_loader)):.0f}%), Mean Loss: {loss_mean:.2f}, F1: {F1_score:.2f}')\n",
    "\n",
    "\n",
    "def validate(model, val_loader, criterion, epoch):\n",
    "    model.eval()\n",
    "    outputlist = []\n",
    "    val_loss = 0\n",
    "    TP,FP,TN,FN = 0,0,0,0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, _) in enumerate(val_loader):\n",
    "            (candidates, candidates_length), (jobs, job_length), ratings = data\n",
    "            batch_s = len(candidates_length)\n",
    "            \n",
    "            candidates = candidates.long().to(device)\n",
    "            jobs = jobs.long().to(device)\n",
    "            ratings = ratings.float().to(device)\n",
    "            \n",
    "            ratings = ratings.unsqueeze(1)\n",
    "            hidden_init_candidates = model.init_hidden_candidates(batch_s)\n",
    "            hidden_init_jobs = model.init_hidden_jobs(batch_s)\n",
    "            \n",
    "            output = model(candidates, jobs, hidden_init_candidates, hidden_init_jobs, candidates_length, job_length)\n",
    "            output_flat = [0 if o < 0.5 else 1 for o in output.data]\n",
    "            \n",
    "            for y,yhat in zip(ratings.data, output_flat):\n",
    "                y = int(y)\n",
    "                if yhat == 0:\n",
    "                    if y != yhat:\n",
    "                        FN += 1\n",
    "                    else:\n",
    "                        TN += 1\n",
    "                else:\n",
    "                    if y != yhat:\n",
    "                        FP += 1\n",
    "                    else:\n",
    "                        TP += 1\n",
    "        \n",
    "            outputlist += [output]\n",
    "            val_loss += criterion(output, ratings).item() # sum up batch loss\n",
    "\n",
    "    #print(TP, FN)\n",
    "    acc = (TP + TN)/(TP + TN + FP + FN)\n",
    "    \n",
    "    if TP + FN == 0:\n",
    "        recall = 0    \n",
    "    else:       \n",
    "        recall = TP/(TP + FN)\n",
    "\n",
    "    if TP + FP == 0:\n",
    "        precision = 0\n",
    "    else:\n",
    "        precision = TP/(TP + FP)\n",
    "\n",
    "    if recall + precision == 0:\n",
    "        F1_score = 0\n",
    "    else:\n",
    "        F1_score = 2/(1/recall + 1/precision)\n",
    "    \n",
    "    val_loss /= len(val_loader)\n",
    "    print(f'Epoch {epoch}: Validation average loss: {val_loss:.2f} | F1: {F1_score:.2f} | Accuracy: {acc:.2f} \\n' )\n",
    "    return acc, val_loss\n",
    "\n",
    "def trainLoop(epochs, lr=0.001, wd = 1e-6, print_batch_p = 1):\n",
    "    # Define model    \n",
    "    model = CFNN(num_candidates, num_jobs).to(device)\n",
    "    #criterion = nn.MSELoss()\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay = wd)\n",
    "    \n",
    "    accs = []\n",
    "    losses = []\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train(model, train_iter, optimizer, criterion, epoch, print_batch_p)\n",
    "        acc, val_loss = validate(model, val_iter, criterion, epoch)\n",
    "        accs += [acc]\n",
    "        losses += [val_loss]\n",
    "        \n",
    "    plt.plot(range(1,epochs+1),accs)\n",
    "    plt.show()\n",
    "    plt.plot(range(1,epochs+1),losses)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 1 (49%), Mean Loss: 12.48, F1: 0.69\n",
      "Train epoch 1 (99%), Mean Loss: 13.51, F1: 0.67\n",
      "Epoch 1: Validation average loss: 14.01 | F1: 0.66 | Accuracy: 0.50 \n",
      "\n",
      "Train epoch 2 (49%), Mean Loss: 13.85, F1: 0.67\n",
      "Train epoch 2 (99%), Mean Loss: 13.88, F1: 0.67\n",
      "Epoch 2: Validation average loss: 14.01 | F1: 0.66 | Accuracy: 0.50 \n",
      "\n",
      "Train epoch 3 (49%), Mean Loss: 14.05, F1: 0.66\n",
      "Train epoch 3 (99%), Mean Loss: 13.86, F1: 0.66\n",
      "Epoch 3: Validation average loss: 14.01 | F1: 0.66 | Accuracy: 0.50 \n",
      "\n",
      "Train epoch 4 (49%), Mean Loss: 13.78, F1: 0.67\n",
      "Train epoch 4 (99%), Mean Loss: 13.85, F1: 0.67\n",
      "Epoch 4: Validation average loss: 14.01 | F1: 0.66 | Accuracy: 0.50 \n",
      "\n",
      "Train epoch 5 (49%), Mean Loss: 13.82, F1: 0.67\n",
      "Train epoch 5 (99%), Mean Loss: 13.84, F1: 0.67\n",
      "Epoch 5: Validation average loss: 14.01 | F1: 0.66 | Accuracy: 0.50 \n",
      "\n",
      "Train epoch 6 (49%), Mean Loss: 13.58, F1: 0.67\n",
      "Train epoch 6 (99%), Mean Loss: 13.93, F1: 0.66\n",
      "Epoch 6: Validation average loss: 14.01 | F1: 0.66 | Accuracy: 0.50 \n",
      "\n",
      "Train epoch 7 (49%), Mean Loss: 13.18, F1: 0.69\n",
      "Train epoch 7 (99%), Mean Loss: 13.84, F1: 0.67\n",
      "Epoch 7: Validation average loss: 14.01 | F1: 0.66 | Accuracy: 0.50 \n",
      "\n",
      "Train epoch 8 (49%), Mean Loss: 14.66, F1: 0.64\n",
      "Train epoch 8 (99%), Mean Loss: 13.89, F1: 0.66\n",
      "Epoch 8: Validation average loss: 14.01 | F1: 0.66 | Accuracy: 0.50 \n",
      "\n",
      "Train epoch 9 (49%), Mean Loss: 13.92, F1: 0.66\n",
      "Train epoch 9 (83%), Mean Loss: 13.82, F1: 0.67\n",
      "Train epoch 9 (99%), Mean Loss: 13.90, F1: 0.66\n",
      "Epoch 9: Validation average loss: 14.01 | F1: 0.66 | Accuracy: 0.50 \n",
      "\n",
      "Train epoch 10 (49%), Mean Loss: 13.71, F1: 0.67\n",
      "Train epoch 10 (99%), Mean Loss: 13.84, F1: 0.67\n",
      "Epoch 10: Validation average loss: 14.01 | F1: 0.66 | Accuracy: 0.50 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainLoop(epochs=10, lr=1, wd=1e-6, print_batch_p=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

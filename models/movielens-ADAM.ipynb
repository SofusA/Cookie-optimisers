{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering\n",
    "With your best friends; Cookie Optimizers :D "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MovieLens\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def condence(nparr):\n",
    "    uniq = np.unique(nparr)\n",
    "    name2idx = {o:i for i,o in enumerate(uniq)}\n",
    "    return np.array([name2idx[o] for o in nparr])\n",
    "\n",
    "class MovieLensDataset(Dataset):\n",
    "    def __init__(self, filename):\n",
    "        self.rawdata = pd.read_csv(filename)\n",
    "        self.rawdata[\"userId\"] = condence(self.rawdata[\"userId\"].values)\n",
    "        self.rawdata[\"movieId\"] = condence(self.rawdata[\"movieId\"].values)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.rawdata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx = idx.item()\n",
    "        users = self.rawdata.iloc[idx, 0]\n",
    "        items = self.rawdata.iloc[idx, 1]\n",
    "        ratings = self.rawdata.iloc[idx, 2]\n",
    "        \n",
    "        return (users, items, ratings)\n",
    "    \n",
    "    def items (self):\n",
    "        n_users = self.rawdata[\"userId\"].nunique()\n",
    "        n_items = self.rawdata[\"movieId\"].nunique()\n",
    "        \n",
    "        return [n_users, n_items]\n",
    "\n",
    "def getLoaders(dataset, batchsize, shuffle, sizes):\n",
    "    train_size = int(sizes[0] * len(dataset))\n",
    "    val_size = int(sizes[1] * len(dataset))\n",
    "    test_size = len(dataset) - train_size - val_size\n",
    "    train_data, val_data, test_data = random_split(dataset, [train_size, val_size, test_size])\n",
    "    \n",
    "    return [DataLoader(data, batch_size = batchsize, shuffle = shuffle) for data in [train_data, val_data, test_data]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copied and adapted from\n",
    "# https://blog.fastforwardlabs.com/2018/04/10/pytorch-for-recommenders-101.html\n",
    "class CFM(torch.nn.Module):\n",
    "    def __init__(self, n_users, n_items, n_factors):\n",
    "        super().__init__()\n",
    "        \n",
    "        # create user embeddings\n",
    "        self.user_factors = torch.nn.Embedding(n_users, n_factors)\n",
    "        # create item embeddings\n",
    "        self.item_factors = torch.nn.Embedding(n_items, n_factors)\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        # matrix multiplication\n",
    "        return (self.user_factors(user)*self.item_factors(item)).sum(1)\n",
    "\n",
    "    def predict(self, user, item):\n",
    "        return self.forward(user, item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traning Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for (users, items, ratings) in train_loader:\n",
    "        users = users.long().to(device)\n",
    "        items = items.long().to(device)\n",
    "        ratings = ratings.float().to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(users, items)\n",
    "        loss = criterion(output, ratings)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    return train_loss / len(train_loader)\n",
    "    \n",
    "\n",
    "def validate(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for (users, items, ratings) in val_loader:\n",
    "            users = users.long().to(device)\n",
    "            items = items.long().to(device)\n",
    "            ratings = ratings.float().to(device)\n",
    "            ratings = ratings.unsqueeze(1)\n",
    "            \n",
    "            output = model(users, items)\n",
    "            loss = criterion(output, ratings)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    return val_loss / len(val_loader)\n",
    "\n",
    "def train_model(train_loader, val_loader, max_epochs, batchsize, model, criterion, optimizer, modelpath=None):\n",
    "    # check path for early stopping\n",
    "    if modelpath != None:\n",
    "        patience_count = 0\n",
    "        torch.save(model, modelpath)\n",
    "    \n",
    "    # Train model\n",
    "    best_loss = (-1, -1, 1e15)\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for epoch in range(1, max_epochs + 1):\n",
    "        # train and validate\n",
    "        train_loss = train(model, train_loader, optimizer, criterion)\n",
    "        val_loss = validate(model, val_loader, criterion)\n",
    "        \n",
    "        val_losses += [val_loss]\n",
    "        train_losses += [train_loss]\n",
    "        print(f'Epoch {epoch:3d} | Train average loss: {train_loss:3.5f} | Validation average loss: {val_loss:3.5f}')\n",
    "        \n",
    "        # Early stopping\n",
    "        if val_loss < best_loss[2]:\n",
    "            best_loss = (epoch, train_loss, val_loss)\n",
    "            \n",
    "            if modelpath != None:\n",
    "                patience_count = 0\n",
    "                torch.save(model, modelpath)\n",
    "        if modelpath != None:\n",
    "            if patience_count == 10:\n",
    "                model = torch.load(modelpath)\n",
    "                break\n",
    "            else:\n",
    "                patience_count += 1\n",
    "\n",
    "    # Plot loss\n",
    "    plt.plot(range(1,epoch+1), val_losses, color='b')\n",
    "    plt.plot(range(1,epoch+1), train_losses, color='g')\n",
    "    plt.axvline(x=best_loss[0], color='r')\n",
    "    plt.show()\n",
    "    print(f\"Best validation loss at epoch {best_loss[0]} | Train loss: {best_loss[1]:.5} | Validation loss {best_loss[2]:.5}\")\n",
    "    \n",
    "    # return loaded model if early stop otherwise, finished model.\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data params\n",
    "datasetpath = '../datasets/movielens/ratings.csv'\n",
    "#datasetpath = '../datasets/movielens-small/ratings.csv'\n",
    "shuffle_data = True\n",
    "size_splits = [0.8, 0.1, 0.1]\n",
    "dataset = MovieLensDataset(datasetpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model params\n",
    "n_users, n_items = dataset.items()\n",
    "emb_size=500\n",
    "model = CFM(n_users, n_items, emb_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training params\n",
    "modelpath = '../torch_models/movielens/best.pth'\n",
    "max_epochs = 1000\n",
    "batch_size = 5\n",
    "learning_rate = 0.001\n",
    "weight_decay = 1e-6\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CFM(\n",
      "  (user_factors): Embedding(283228, 500)\n",
      "  (item_factors): Embedding(53889, 500)\n",
      ") \n",
      "\n",
      "Amount of batches in training set:   4440551 | Total samples: 22202755\n",
      "Amount of batches in validation set:  555069 | Total samples:  2775345\n",
      "Amount of batches in testing set:     555069 | Total samples:  2775345\n"
     ]
    }
   ],
   "source": [
    "# Data loaders\n",
    "train_loader, val_loader, test_loader = getLoaders(dataset, batch_size, shuffle_data, size_splits)\n",
    "\n",
    "# Print info on model and loaders\n",
    "ls = [len(l) for l in [train_loader, val_loader, test_loader]]\n",
    "mbls = max([len(str(l)) for l in ls])\n",
    "mls = max([len(str(l*batch_size)) for l in ls])\n",
    "\n",
    "print(model, \"\\n\")\n",
    "print(f\"Amount of batches in training set:   {ls[0]:{mbls}d} | Total samples: {ls[0]*batch_size:{mls}d}\")\n",
    "print(f\"Amount of batches in validation set: {ls[1]:{mbls}d} | Total samples: {ls[1]*batch_size:{mls}d}\")\n",
    "print(f\"Amount of batches in testing set:    {ls[2]:{mbls}d} | Total samples: {ls[2]*batch_size:{mls}d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-34d082f70b25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                             \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                             \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                             modelpath)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-710b748014b6>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(train_loader, val_loader, max_epochs, batchsize, model, criterion, optimizer, modelpath)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;31m# train and validate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-710b748014b6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer, criterion)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory"
     ]
    }
   ],
   "source": [
    "model_trained = train_model(train_loader,\n",
    "                            val_loader, \n",
    "                            max_epochs, \n",
    "                            batch_size, \n",
    "                            model, \n",
    "                            criterion, \n",
    "                            optimizer, \n",
    "                            modelpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trained.eval()\n",
    "test_loss = 0\n",
    "with torch.no_grad():\n",
    "    for (users, items, ratings) in test_loader:\n",
    "        users = users.long().to(device)\n",
    "        items = items.long().to(device)\n",
    "        ratings = ratings.float().to(device)\n",
    "        output = model_trained(users, items)\n",
    "\n",
    "        test_loss += criterion(output, ratings).item() # sum up batch loss\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "# UNCOMMENT ONLY WHEN MODEL IS COMPLETELY FINISHED\n",
    "print(f'Final test average loss: {test_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

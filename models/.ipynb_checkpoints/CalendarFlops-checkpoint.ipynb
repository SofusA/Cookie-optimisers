{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CalendarFlops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: de_core_news_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.0.0/de_core_news_sm-2.0.0.tar.gz#egg=de_core_news_sm==2.0.0 in /opt/conda/lib/python3.6/site-packages (2.0.0)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\n",
      "\u001b[93m    Linking successful\u001b[0m\n",
      "    /opt/conda/lib/python3.6/site-packages/de_core_news_sm -->\n",
      "    /opt/conda/lib/python3.6/site-packages/spacy/data/de\n",
      "\n",
      "    You can now load the model via spacy.load('de')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Dataset, BucketIterator, Field, TabularDataset, Iterator\n",
    "from torchtext.vocab import Vocab\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "from torchtext.vocab import Vectors\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read set\n",
    "#data='../datasets/TalentFox/processed_dataset-small.csv'\n",
    "data='../datasets/TalentFox/processed_dataset.csv'\n",
    "\n",
    "parced_data = pd.read_csv(data)\n",
    "parced_data = parced_data[['candidate_resume','job_description', 'match_status']]\n",
    "parced_data['match_status'] = parced_data['match_status'][pd.to_numeric(parced_data['match_status'], errors='coerce').notnull()]\n",
    "parced_data = parced_data.dropna()\n",
    "\n",
    "#Flat\n",
    "parced_data['match_status'] = parced_data['match_status'].apply(lambda x: 0 if int(x) < 4 else 1)\n",
    "\n",
    "# Drop to equal\n",
    "parced_data = parced_data.sort_values(by=['match_status'], ascending=False)\n",
    "count = pd.value_counts(parced_data['match_status'].values, sort=False)\n",
    "count = count[1]\n",
    "parced_data = parced_data[:2*count]\n",
    "\n",
    "# Shuffle\n",
    "parced_data = parced_data.sample(frac=1)\n",
    "\n",
    "max_length_candidates = max((len(s.split(' ')) for s in parced_data['candidate_resume']))\n",
    "max_length_jobs = max((len(s.split(' ')) for s in parced_data['job_description']))\n",
    "\n",
    "sizes = [0.7, 0.2]\n",
    "n = len(parced_data)\n",
    "\n",
    "train_size = int(sizes[0] * n)\n",
    "val_size = int(sizes[1] * n)\n",
    "test_size = n - train_size - val_size\n",
    "\n",
    "train = parced_data[:train_size]\n",
    "val = parced_data[train_size:train_size+val_size]\n",
    "test = parced_data[train_size+val_size:]\n",
    "\n",
    "val.to_csv('../datasets/TalentFox/val.csv', header = False, index = False)\n",
    "test.to_csv('../datasets/TalentFox/test.csv', header = False, index = False)\n",
    "train.to_csv('../datasets/TalentFox/train.csv', header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_de = spacy.load('de')\n",
    "\n",
    "vec_url = 'https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki.de.vec'\n",
    "\n",
    "def tokenizer(text): # create a tokenizer function\n",
    "    return [tok.text for tok in spacy_de.tokenizer(text)]\n",
    "\n",
    "CANDIDATES = Field(sequential=True, lower=True, include_lengths=True, fix_length=max_length_candidates)\n",
    "LABEL = Field(sequential=False, use_vocab=False)\n",
    "JOBS = Field(sequential=True, lower=True, include_lengths=True, fix_length=max_length_jobs)\n",
    "\n",
    "train, val, test = TabularDataset.splits(\n",
    "        path='../datasets/TalentFox', train='train.csv',\n",
    "        validation='val.csv', test='test.csv', format='csv',\n",
    "        fields=[('Candidates', CANDIDATES), ('Jobs', JOBS), ('Label', LABEL)])\n",
    "\n",
    "CANDIDATES.build_vocab(train, vectors=Vectors('wiki.de.vec', url=vec_url))\n",
    "LABEL.build_vocab(train)\n",
    "JOBS.build_vocab(train, vectors=Vectors('wiki.de.vec', url=vec_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text fields:\n",
      " Size of  job vocabulary: 7745\n",
      " Size of users vocabulary: 19807\n",
      " no. times the \"das\" appear in the dataset: 192\n",
      " Max length: Candidates: 3541, Jobs: 351\n"
     ]
    }
   ],
   "source": [
    "print('Text fields:')\n",
    "print(f' Size of  job vocabulary: {len(JOBS.vocab)}')\n",
    "print(f' Size of users vocabulary: {len(CANDIDATES.vocab)}')\n",
    "print(' no. times the \"das\" appear in the dataset:', JOBS.vocab.freqs['das']+CANDIDATES.vocab.freqs['das'])\n",
    "print(f' Max length: Candidates: {max_length_candidates}, Jobs: {max_length_jobs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = (100, 101, 102)\n",
    "\n",
    "train_iter, val_iter, test_iter = BucketIterator.splits(\n",
    "    (train, val, test), batch_sizes = batch_size, sort_key=lambda x: len(x.Jobs), sort_within_batch = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of candidates: 19807, Number of jobs: 7745\n",
      "Candidates embedding dim 300\n",
      "Job embedding dim 300\n"
     ]
    }
   ],
   "source": [
    "# size of embeddings\n",
    "embedding_dim_candidates = CANDIDATES.vocab.vectors.size()[1]\n",
    "embedding_dim_jobs = JOBS.vocab.vectors.size()[1]\n",
    "num_jobs = JOBS.vocab.vectors.size()[0]\n",
    "num_candidates = CANDIDATES.vocab.vectors.size()[0]\n",
    "print(f'Number of candidates: {num_candidates}, Number of jobs: {num_jobs}')\n",
    "\n",
    "print(f'Candidates embedding dim {embedding_dim_candidates}')\n",
    "print(f'Job embedding dim {embedding_dim_jobs}')\n",
    "\n",
    "n_hidden = 91\n",
    "l1_hidden = 92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFNN(nn.Module):\n",
    "    def __init__(self, num_candidates,\n",
    "                 num_jobs,\n",
    "                 embedding_dim_candidates=embedding_dim_candidates,\n",
    "                 embedding_dim_jobs=embedding_dim_jobs,\n",
    "                 n_hidden=n_hidden,\n",
    "                 l1_hidden=l1_hidden):\n",
    "        super(CFNN, self).__init__()\n",
    "        \n",
    "        self.candidates_emb = nn.Embedding(num_candidates, embedding_dim_candidates)       \n",
    "        self.jobs_emb = nn.Embedding(num_jobs, embedding_dim_jobs)\n",
    "               \n",
    "        self.lin1 = nn.Linear(embedding_dim_candidates + n_hidden, l1_hidden)\n",
    "        self.lin2 = nn.Linear(l1_hidden, 1)\n",
    "        self.drop0 = nn.Dropout(0.1)\n",
    "        self.drop1 = nn.Dropout(0.1)\n",
    "                \n",
    "        ### RNN decoding\n",
    "        # Candidates\n",
    "        self.rnn_candidates = nn.LSTM(embedding_dim_candidates, n_hidden, batch_first = False)\n",
    "        self.rnnlin_candidates = nn.Linear(embedding_dim_candidates, n_hidden)\n",
    "        \n",
    "        # Jobs\n",
    "        self.rnn_jobs = nn.LSTM(embedding_dim_jobs, n_hidden, batch_first = False)\n",
    "        self.rnnlin_jobs = nn.Linear(100, n_hidden)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, c, j, hidden_candidates, hidden_jobs, candidates_length, job_length):\n",
    "        C = self.candidates_emb(c)\n",
    "        J = self.jobs_emb(j)\n",
    "        batch_size = len(candidates_length)\n",
    "        \n",
    "        # Masking and meaning Candidates\n",
    "        mask_candidates = list()\n",
    "        for i in range(batch_size):\n",
    "            l = candidates_length.data[0].item()\n",
    "            m = [1]*l + [0]*(max_length_candidates-l)\n",
    "            mask_candidates += [m]       \n",
    "        mask_candidates = torch.from_numpy(np.array(mask_candidates)).to(device).float().transpose(0,1)             \n",
    "        mask_candidates = mask_candidates.unsqueeze(2)\n",
    "        \n",
    "        C = C * mask_candidates\n",
    "        C = torch.mean(C, dim=0) #mean all embeddings\n",
    "        \n",
    "        ## RNN Jobs\n",
    "        packed = rnn_utils.pack_padded_sequence(J, job_length).to(device)\n",
    "        rnnOut, (hn, cn) = self.rnn_jobs(packed, hidden_jobs)\n",
    "        padded, seq_lengths = rnn_utils.pad_packed_sequence(rnnOut, padding_value=0, total_length=max_length_jobs)\n",
    "        seq_lengths = seq_lengths.to(device).float()\n",
    "        \n",
    "        # Divide each batch_element by sequence_element and sum. (mean by seq_length)\n",
    "        padded = (padded.transpose(1,2) / seq_lengths).transpose(1,2)\n",
    "        J = padded.sum(dim=0)\n",
    "        \n",
    "        x = F.relu(torch.cat([C, J], dim=1))\n",
    "        \n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = F.relu(self.lin2(x))\n",
    "\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "    def init_hidden_candidates(self, batch_size):\n",
    "        init = torch.zeros(1, batch_size, n_hidden).to(device)\n",
    "        return (init,init)\n",
    "    \n",
    "    def init_hidden_jobs(self, batch_size):\n",
    "        init = torch.zeros(1, batch_size, n_hidden).to(device)\n",
    "        return (init,init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training loop\n",
    "def train(model, train_loader, optimizer, criterion, epoch, print_batch_p):\n",
    "    model.train()\n",
    "    \n",
    "    TP,FP,TN,FN = 0,0,0,0\n",
    "    loss_list = []\n",
    "    \n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        (candidates, candidates_length), (jobs, job_length), ratings = data\n",
    "                   \n",
    "        batch_s = len(candidates_length)\n",
    "        \n",
    "        candidates = candidates.long().to(device)\n",
    "        jobs = jobs.long().to(device)\n",
    "        ratings = ratings.float().to(device)      \n",
    "        ratings = ratings.view(-1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        hidden_init_candidates = model.init_hidden_candidates(batch_s)\n",
    "        hidden_init_jobs = model.init_hidden_jobs(batch_s)\n",
    "        output = model(candidates, jobs, hidden_init_candidates, hidden_init_jobs, candidates_length, job_length)\n",
    "        output = output.view(-1)\n",
    "                     \n",
    "        loss = criterion(output, ratings)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print jumping\n",
    "        percent = print_batch_p\n",
    "        \n",
    "        proc = int((len(train_loader.dataset)/batch_s)*percent)\n",
    "        proc = proc if proc >= 1 else 1\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        output_flat = [0 if o < 0.5 else 1 for o in output.data]\n",
    "\n",
    "        for y,yhat in zip(ratings.data, output_flat):\n",
    "            y = int(y)\n",
    "            if yhat == 0:\n",
    "                if y != yhat:\n",
    "                    FN += 1\n",
    "                else:\n",
    "                    TN += 1\n",
    "            else:\n",
    "                if y != yhat:\n",
    "                    FP += 1\n",
    "                else:\n",
    "                    TP += 1\n",
    "        loss_list += [loss.item()]\n",
    "        \n",
    "        if batch_idx % proc == 0 and batch_idx != 0:\n",
    "            loss_mean = sum(loss_list)/len(loss_list)\n",
    "            acc = (TP + TN)/(TP+FP+TN+FN)\n",
    "            \n",
    "            if TP + FN == 0:\n",
    "                recall = 0    \n",
    "            else:       \n",
    "                recall = TP/(TP + FN)\n",
    "                \n",
    "            if TP + FP == 0:\n",
    "                precision = 0\n",
    "            else:\n",
    "                precision = TP/(TP + FP)\n",
    "            \n",
    "            \n",
    "            if recall + precision == 0:\n",
    "                F1_score = 0\n",
    "            else:\n",
    "                F1_score = 2/(1/recall + 1/precision)\n",
    "            \n",
    "            #TP,FP,TN,FN = 0,0,0,0\n",
    "            #loss_list = []\n",
    "            print(f'Train epoch {epoch} ({100 * (batch_idx / len(train_loader)):.0f}%), Mean Loss: {loss_mean:.2f}, F1: {F1_score:.2f}')\n",
    "\n",
    "\n",
    "def validate(model, val_loader, criterion, epoch):\n",
    "    model.eval()\n",
    "    outputlist = []\n",
    "    val_loss = 0\n",
    "    TP,FP,TN,FN = 0,0,0,0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, _) in enumerate(val_loader):\n",
    "            (candidates, candidates_length), (jobs, job_length), ratings = data\n",
    "            batch_s = len(candidates_length)\n",
    "            \n",
    "            candidates = candidates.long().to(device)\n",
    "            jobs = jobs.long().to(device)\n",
    "            ratings = ratings.float().to(device)\n",
    "            \n",
    "            ratings = ratings.unsqueeze(1)\n",
    "            hidden_init_candidates = model.init_hidden_candidates(batch_s)\n",
    "            hidden_init_jobs = model.init_hidden_jobs(batch_s)\n",
    "            \n",
    "            output = model(candidates, jobs, hidden_init_candidates, hidden_init_jobs, candidates_length, job_length)\n",
    "            output_flat = [0 if o < 0.5 else 1 for o in output.data]\n",
    "            \n",
    "            for y,yhat in zip(ratings.data, output_flat):\n",
    "                y = int(y)\n",
    "                if yhat == 0:\n",
    "                    if y != yhat:\n",
    "                        FN += 1\n",
    "                    else:\n",
    "                        TN += 1\n",
    "                else:\n",
    "                    if y != yhat:\n",
    "                        FP += 1\n",
    "                    else:\n",
    "                        TP += 1\n",
    "        \n",
    "            outputlist += [output]\n",
    "            val_loss += criterion(output, ratings).item() # sum up batch loss\n",
    "\n",
    "    #print(TP, FN)\n",
    "    acc = (TP + TN)/(TP + TN + FP + FN)\n",
    "    \n",
    "    if TP + FN == 0:\n",
    "        recall = 0    \n",
    "    else:       \n",
    "        recall = TP/(TP + FN)\n",
    "\n",
    "    if TP + FP == 0:\n",
    "        precision = 0\n",
    "    else:\n",
    "        precision = TP/(TP + FP)\n",
    "\n",
    "    if recall + precision == 0:\n",
    "        F1_score = 0\n",
    "    else:\n",
    "        F1_score = 2/(1/recall + 1/precision)\n",
    "    \n",
    "    val_loss /= len(val_loader)\n",
    "    print(f'Epoch {epoch}: Validation average loss: {val_loss:.2f} | F1: {F1_score:.2f} | Accuracy: {acc:.2f} \\n' )\n",
    "    return acc, val_loss\n",
    "\n",
    "def trainLoop(epochs, lr=0.001, wd = 1e-6, print_batch_p = 1):\n",
    "    # Define model    \n",
    "    model = CFNN(num_candidates, num_jobs).to(device)\n",
    "    #criterion = nn.MSELoss()\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay = wd)\n",
    "    \n",
    "    accs = []\n",
    "    losses = []\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train(model, train_iter, optimizer, criterion, epoch, print_batch_p)\n",
    "        acc, val_loss = validate(model, val_iter, criterion, epoch)\n",
    "        accs += [acc]\n",
    "        losses += [val_loss]\n",
    "        \n",
    "    plt.plot(range(1,epochs+1),accs)\n",
    "    plt.show()\n",
    "    plt.plot(range(1,epochs+1),losses)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch 1 (40%), Mean Loss: 0.69, F1: 0.67\n",
      "Train epoch 1 (80%), Mean Loss: 0.69, F1: 0.69\n",
      "Epoch 1: Validation average loss: 0.72 | F1: 0.65 | Accuracy: 0.48 \n",
      "\n",
      "Train epoch 2 (40%), Mean Loss: 0.72, F1: 0.67\n",
      "Train epoch 2 (80%), Mean Loss: 0.71, F1: 0.69\n",
      "Epoch 2: Validation average loss: 0.69 | F1: 0.65 | Accuracy: 0.48 \n",
      "\n",
      "Train epoch 3 (40%), Mean Loss: 0.69, F1: 0.61\n",
      "Train epoch 3 (80%), Mean Loss: 0.69, F1: 0.69\n",
      "Epoch 3: Validation average loss: 0.69 | F1: 0.65 | Accuracy: 0.48 \n",
      "\n",
      "Train epoch 4 (40%), Mean Loss: 0.69, F1: 0.67\n",
      "Epoch 4: Validation average loss: 0.69 | F1: 0.65 | Accuracy: 0.48 \n",
      "\n",
      "Train epoch 5 (40%), Mean Loss: 0.69, F1: 0.66\n",
      "Train epoch 5 (80%), Mean Loss: 0.69, F1: 0.69\n",
      "Epoch 5: Validation average loss: 0.69 | F1: 0.65 | Accuracy: 0.48 \n",
      "\n",
      "Train epoch 6 (40%), Mean Loss: 0.69, F1: 0.72\n",
      "Train epoch 6 (80%), Mean Loss: 0.69, F1: 0.69\n",
      "Epoch 6: Validation average loss: 0.69 | F1: 0.65 | Accuracy: 0.48 \n",
      "\n",
      "Train epoch 7 (80%), Mean Loss: 0.69, F1: 0.69\n",
      "Epoch 7: Validation average loss: 0.69 | F1: 0.65 | Accuracy: 0.48 \n",
      "\n",
      "Train epoch 8 (40%), Mean Loss: 0.69, F1: 0.61\n",
      "Train epoch 8 (80%), Mean Loss: 0.69, F1: 0.69\n",
      "Epoch 8: Validation average loss: 0.69 | F1: 0.65 | Accuracy: 0.48 \n",
      "\n",
      "Train epoch 9 (40%), Mean Loss: 0.69, F1: 0.67\n",
      "Epoch 9: Validation average loss: 0.69 | F1: 0.65 | Accuracy: 0.48 \n",
      "\n",
      "Train epoch 10 (40%), Mean Loss: 0.69, F1: 0.67\n",
      "Epoch 10: Validation average loss: 0.69 | F1: 0.65 | Accuracy: 0.48 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainLoop(epochs=10, lr=0.1, wd=1e-6, print_batch_p=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
